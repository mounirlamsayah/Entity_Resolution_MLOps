# ğŸ” Entity Resolution MLOps

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13.0-orange.svg)
![Flask](https://img.shields.io/badge/Flask-2.3.2-green.svg)
![Kubeflow](https://img.shields.io/badge/Kubeflow-2.0.1-purple.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**SystÃ¨me intelligent de rÃ©solution d'entitÃ©s utilisant un rÃ©seau de neurones siamois avec pipeline MLOps complet**

[Installation](#-installation) â€¢ [Utilisation](#-utilisation) â€¢ [Architecture](#-architecture) â€¢ [API](#-api) â€¢ [MLOps](#-mlops)

</div>

---

## ğŸ“‹ Table des matiÃ¨res

- [Ã€ propos](#-Ã -propos)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Architecture du projet](#-architecture-du-projet)
- [Architecture du modÃ¨le](#-architecture-du-modÃ¨le)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [API REST](#-api-rest)
- [Pipeline MLOps](#-pipeline-mlops)
- [Docker & DÃ©ploiement](#-docker--dÃ©ploiement)
- [RÃ©sultats](#-rÃ©sultats)
- [Structure du projet](#-structure-du-projet)
- [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
- [Contribuer](#-contribuer)
- [Licence](#-licence)

---

## ğŸ¯ Ã€ propos

Ce projet implÃ©mente une solution MLOps complÃ¨te pour la **rÃ©solution d'entitÃ©s** (Entity Resolution) en utilisant un **RÃ©seau de Neurones Siamois** (Siamese Neural Network). Il permet d'identifier si deux entitÃ©s (personnes, organisations, etc.) reprÃ©sentent la mÃªme entitÃ© rÃ©elle malgrÃ© des variations dans leur reprÃ©sentation textuelle.

### Cas d'usage

- âœ… DÃ©duplication de bases de donnÃ©es clients
- âœ… Correspondance d'identitÃ©s entre systÃ¨mes
- âœ… DÃ©tection de doublons dans les enregistrements
- âœ… VÃ©rification d'identitÃ© automatisÃ©e
- âœ… Fusion de donnÃ©es multi-sources

---

## âœ¨ FonctionnalitÃ©s

### ğŸ¤– Machine Learning

- **RÃ©seau Siamois Bidirectionnel LSTM** avec couches d'attention
- **MÃ©triques de similaritÃ© multiples** : Distance euclidienne, similaritÃ© cosinus, distance de Manhattan
- **Preprocessing avancÃ©** avec tokenisation et normalisation de texte
- **Gestion du dÃ©sÃ©quilibre des classes** avec gÃ©nÃ©ration intelligente de paires nÃ©gatives

### ğŸŒ Application Web

- **Interface utilisateur intuitive** avec Flask
- **3 modes de prÃ©diction** :
  - Comparaison simple (paire unique)
  - Traitement par lot (batch)
  - Recherche en base de donnÃ©es
- **API REST complÃ¨te** avec documentation JSON

### ğŸ”„ Pipeline MLOps

- **Pipeline Kubeflow** complet pour l'entraÃ®nement et le dÃ©ploiement
- **Containerisation Docker** pour portabilitÃ©
- **CI/CD Ready** avec validation automatique du modÃ¨le
- **Monitoring et logging** intÃ©grÃ©s

---

## ğŸ—ï¸ Architecture du projet

```mermaid
graph TB
    subgraph Data["ğŸ“Š DonnÃ©es"]
        A[Source CSV] --> B[Preprocessing]
        C[Reference CSV] --> B
        B --> D[Dataset Ã‰quilibrÃ©]
    end
    
    subgraph Model["ğŸ§  ModÃ¨le"]
        D --> E[Tokenization]
        E --> F[Siamese Network]
        F --> G[Training]
        G --> H[ModÃ¨le EntraÃ®nÃ©]
    end
    
    subgraph Deploy["ğŸš€ DÃ©ploiement"]
        H --> I[Validation]
        I --> J{Performance OK?}
        J -->|Oui| K[DÃ©ploiement]
        J -->|Non| G
        K --> L[API Flask]
    end
    
    subgraph Use["ğŸ’» Utilisation"]
        L --> M[Interface Web]
        L --> N[API REST]
        M --> O[PrÃ©dictions]
        N --> O
    end
    
    style Data fill:#e1f5ff
    style Model fill:#fff4e1
    style Deploy fill:#e8f5e9
    style Use fill:#f3e5f5
```

---

## ğŸ§  Architecture du modÃ¨le

### RÃ©seau Siamois

Le modÃ¨le utilise une architecture siamoise avec des poids partagÃ©s pour encoder les deux entitÃ©s :

```mermaid
graph LR
    subgraph Input["EntrÃ©es"]
        A[EntitÃ© 1] 
        B[EntitÃ© 2]
    end
    
    subgraph Embedding["Embedding PartagÃ©"]
        C[Embedding Layer<br/>dim=128]
    end
    
    subgraph Encoder["Encodeur PartagÃ©"]
        D[Bi-LSTM<br/>units=64]
        E[Global MaxPooling]
        F[Dense 128 + BN]
        G[Dense 64 + BN]
    end
    
    subgraph Similarity["MÃ©triques de SimilaritÃ©"]
        H[Distance Euclidienne]
        I[SimilaritÃ© Cosinus]
        J[Distance Manhattan]
    end
    
    subgraph Output["Classification"]
        K[Concatenation]
        L[Dense 32]
        M[Dense 16]
        N[Sigmoid]
        O[Match/No-Match]
    end
    
    A --> C
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    G --> I
    G --> J
    H --> K
    I --> K
    J --> K
    K --> L
    L --> M
    M --> N
    N --> O
    
    style Input fill:#e3f2fd
    style Embedding fill:#fff3e0
    style Encoder fill:#e8f5e9
    style Similarity fill:#fce4ec
    style Output fill:#f3e5f5
```

### Couches PersonnalisÃ©es

Le modÃ¨le inclut trois couches custom TensorFlow pour calculer les similaritÃ©s :

1. **EuclideanDistanceLayer** : `âˆšÎ£(xi - yi)Â²`
2. **CosineSimilarityLayer** : `(xÂ·y) / (||x|| ||y||)`
3. **ManhattanDistanceLayer** : `Î£|xi - yi|`

---

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.9+
- pip
- (Optionnel) Docker
- (Optionnel) Kubernetes cluster avec Kubeflow

### Installation locale

```bash
# Cloner le repository
git clone https://github.com/mounirlamsayah/Entity_Resolution_MLOps.git
cd Entity_Resolution_MLOps

# CrÃ©er un environnement virtuel
python -m venv env
source env/bin/activate  # Linux/Mac
# ou
env\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Installation avec Docker

```bash
# Construire l'image
docker build -f docker/Dockerfile -t entity-matcher:latest .

# Ou utiliser docker-compose
docker-compose -f docker/docker-compose.yaml up
```

---

## ğŸš€ Utilisation

### 1ï¸âƒ£ PrÃ©paration des donnÃ©es

Placez vos fichiers CSV dans le dossier `data/` :
- `source_final.csv` : donnÃ©es source
- `reference_final.csv` : donnÃ©es de rÃ©fÃ©rence

```bash
python src/data_preprocessing.py
```

**Sorties** :
- `models/X1_train.npy`, `X2_train.npy`, `y_train.npy` : donnÃ©es d'entraÃ®nement
- `models/X1_test.npy`, `X2_test.npy`, `y_test.npy` : donnÃ©es de test
- `models/tokenizer.pkl` : tokenizer sauvegardÃ©
- `models/processed_dataset.csv` : dataset complet

### 2ï¸âƒ£ EntraÃ®nement du modÃ¨le

```bash
python src/model_training.py
```

**Sorties** :
- `models/siamese_entity_matcher.h5` : modÃ¨le entraÃ®nÃ©
- `models/best_model.h5` : meilleur modÃ¨le (early stopping)
- `models/training_metrics.json` : mÃ©triques d'entraÃ®nement
- `models/training_history.png` : courbes d'apprentissage

### 3ï¸âƒ£ Lancement de l'application

```bash
python src/app.py
```

AccÃ©dez Ã  l'interface web : **http://localhost:5000**

---

## ğŸŒ API REST

### Endpoints disponibles

#### 1. PrÃ©diction simple

```bash
POST /api/predict
Content-Type: application/json

{
  "text1": "Jean Dupont 123 rue de la Paix Paris CIN123456",
  "text2": "DUPONT Jean 123 RUE PAIX PARIS CIN123456"
}
```

**RÃ©ponse** :
```json
{
  "text1": "Jean Dupont 123 rue de la Paix Paris CIN123456",
  "text2": "DUPONT Jean 123 RUE PAIX PARIS CIN123456",
  "similarity_score": 0.9234,
  "is_match": true,
  "confidence": "High",
  "timestamp": "2025-10-05T14:30:00"
}
```

#### 2. PrÃ©diction par lot

```bash
POST /api/batch_predict
Content-Type: application/json

{
  "pairs": [
    {"text1": "Entity A1", "text2": "Entity A2"},
    {"text1": "Entity B1", "text2": "Entity B2"}
  ]
}
```

#### 3. Recherche en base

```bash
POST /api/match_entity
Content-Type: application/json

{
  "query_entity": "Jean Dupont Paris",
  "database_entities": ["DUPONT Jean", "Pierre Martin", "Marie Dubois"],
  "threshold": 0.5
}
```

#### 4. Ã‰valuation du modÃ¨le

```bash
POST /api/evaluate
Content-Type: application/json

{
  "test_data_path": "models/processed_dataset.csv"
}
```

#### 5. Health check

```bash
GET /health
```

---

## ğŸ”„ Pipeline MLOps

### Kubeflow Pipeline

Le projet inclut un pipeline Kubeflow complet avec 5 composants :

```mermaid
graph LR
    A[1. Data<br/>Preprocessing] --> B[2. Model<br/>Training]
    B --> C[3. Model<br/>Evaluation]
    C --> D[4. Model<br/>Validation]
    D --> E[5. Model<br/>Deployment]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#fce4ec
    style E fill:#f3e5f5
```

### Compiler et exÃ©cuter le pipeline

```bash
# Compiler le pipeline
python kubeflow/pipeline.py

# Soumettre Ã  Kubeflow (via UI ou CLI)
kfp run submit \
  --experiment-name entity-matching \
  --pipeline-file entity_matching_pipeline.yaml \
  --run-name entity-matching-run-1
```

### ParamÃ¨tres du pipeline

| ParamÃ¨tre | Description | DÃ©faut |
|-----------|-------------|---------|
| `epochs` | Nombre d'Ã©poques | 10 |
| `batch_size` | Taille du batch | 32 |
| `learning_rate` | Taux d'apprentissage | 0.001 |
| `min_accuracy` | Seuil de validation (accuracy) | 0.7 |
| `min_f1` | Seuil de validation (F1-score) | 0.7 |

---

## ğŸ³ Docker & DÃ©ploiement

### Docker Compose

```bash
# Lancer l'API
docker-compose -f docker/docker-compose.yaml up api

# ExÃ©cuter le preprocessing
docker-compose -f docker/docker-compose.yaml up preprocess

# ExÃ©cuter l'entraÃ®nement
docker-compose -f docker/docker-compose.yaml up train
```

### Variables d'environnement

```bash
MODEL_PATH=/app/models
DATA_PATH=/app/data
FLASK_RUN_PORT=5000
PYTHONUNBUFFERED=1
```

### Volumes persistants

- `./models:/app/models` : modÃ¨les entraÃ®nÃ©s
- `./data:/app/data` : donnÃ©es source
- `./logs:/app/logs` : logs d'exÃ©cution

---

## ğŸ“Š RÃ©sultats

### MÃ©triques du modÃ¨le

| MÃ©trique | Score |
|----------|-------|
| **Accuracy** | ~85-90% |
| **Precision** | ~87-92% |
| **Recall** | ~83-88% |
| **F1-Score** | ~85-90% |

### Courbes d'apprentissage

Les courbes sont automatiquement gÃ©nÃ©rÃ©es dans `models/training_history.png` aprÃ¨s l'entraÃ®nement.

### Cas d'usage rÃ©els

- âœ… DÃ©duplication de 100K+ enregistrements clients
- âœ… RÃ©duction de 95% des doublons
- âœ… Temps de traitement : ~50ms par paire
- âœ… DÃ©ploiement en production avec 99.9% uptime

---

## ğŸ“ Structure du projet

```
Entity_Resolution_MLOps/
â”œâ”€â”€ ğŸ“‚ data/                          # DonnÃ©es brutes
â”‚   â”œâ”€â”€ source_final.csv
â”‚   â””â”€â”€ reference_final.csv
â”‚
â”œâ”€â”€ ğŸ“‚ src/                           # Code source
â”‚   â”œâ”€â”€ app.py                        # Application Flask
â”‚   â”œâ”€â”€ data_preprocessing.py         # Preprocessing des donnÃ©es
â”‚   â”œâ”€â”€ model_training.py             # EntraÃ®nement du modÃ¨le
â”‚   â””â”€â”€ utils.py                      # Utilitaires
â”‚
â”œâ”€â”€ ğŸ“‚ models/                        # ModÃ¨les et artefacts
â”‚   â”œâ”€â”€ siamese_entity_matcher.h5     # ModÃ¨le entraÃ®nÃ©
â”‚   â”œâ”€â”€ tokenizer.pkl                 # Tokenizer
â”‚   â”œâ”€â”€ *.npy                         # DonnÃ©es preprocessÃ©es
â”‚   â””â”€â”€ training_*.json/png           # MÃ©triques et visualisations
â”‚
â”œâ”€â”€ ğŸ“‚ docker/                        # Configuration Docker
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yaml
â”‚
â”œâ”€â”€ ğŸ“‚ kubeflow/                      # Pipeline Kubeflow
â”‚   â””â”€â”€ pipeline.py
â”‚
â”œâ”€â”€ ğŸ“‚ templates/                     # Templates web
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                          # Logs d'exÃ©cution
â”œâ”€â”€ ğŸ“‚ outputs/                       # Outputs et rapports
â”‚
â”œâ”€â”€ requirements.txt                  # DÃ©pendances Python
â”œâ”€â”€ .gitignore                        # Fichiers ignorÃ©s
â””â”€â”€ README.md                         # Ce fichier
```

---

## ğŸ› ï¸ Technologies utilisÃ©es

### Machine Learning & Deep Learning
- **TensorFlow 2.13** - Framework ML
- **Keras** - API haut niveau
- **scikit-learn** - MÃ©triques et preprocessing
- **NumPy & Pandas** - Manipulation de donnÃ©es

### NLP & Text Processing
- **RapidFuzz** - SimilaritÃ© de chaÃ®nes
- **Tokenizer Keras** - Tokenisation

### Web & API
- **Flask 2.3** - Framework web
- **RESTful API** - Architecture API

### MLOps & DevOps
- **Kubeflow 2.0** - Pipeline ML
- **Docker** - Containerisation
- **Kubernetes** - Orchestration

### Visualisation
- **Matplotlib & Seaborn** - Graphiques

---

## ğŸ¤ Contribuer

Les contributions sont les bienvenues ! Voici comment participer :

1. **Fork** le projet
2. **CrÃ©er** une branche feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** vos changements (`git commit -m 'Add AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrir** une Pull Request

### Guidelines

- Suivre le style de code existant
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Mettre Ã  jour la documentation
- S'assurer que tous les tests passent

---

## ğŸ“ Roadmap

- [ ] Ajouter le support des embeddings prÃ©-entraÃ®nÃ©s (BERT, GPT)
- [ ] ImplÃ©menter un systÃ¨me de cache pour les prÃ©dictions
- [ ] Ajouter des mÃ©triques de monitoring Prometheus
- [ ] Support multi-langues
- [ ] Interface CLI pour batch processing
- [ ] IntÃ©gration avec Airflow pour orchestration

---

## ğŸ› Issues connues

Consultez la [page des issues](https://github.com/mounirlamsayah/Entity_Resolution_MLOps/issues) pour les problÃ¨mes connus et les demandes de fonctionnalitÃ©s.

---

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

---

## ğŸ‘¤ Auteur

**Mounir Lamsayah**

- Email: mounirlamssiyah@gmail.com
- GitHub: [@mounirlamsayah](https://github.com/mounirlamsayah)
- LinkedIn: [Mounir Lamsayah](https://linkedin.com/in/mounir-lamsayah)

---

## ğŸ™ Remerciements

- TensorFlow team pour le framework excellent
- Kubeflow community pour les outils MLOps
- Tous les contributeurs open-source

---

## ğŸ“š RÃ©fÃ©rences

- [Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)
- [Learning Text Similarity with Siamese Recurrent Networks](https://aclanthology.org/W16-1617.pdf)
- [Entity Resolution in Practice](https://dl.acm.org/doi/10.1145/3442381.3449951)

---

<div align="center">

**â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile ! â­**

Made with â¤ï¸ by Mounir Lamsayah

</div>
