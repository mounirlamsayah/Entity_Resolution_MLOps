# üîç Entity Resolution MLOps

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13.0-orange.svg)
![Flask](https://img.shields.io/badge/Flask-2.3.2-green.svg)
![Kubeflow](https://img.shields.io/badge/Kubeflow-2.0.1-purple.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)

**Syst√®me intelligent de r√©solution d'entit√©s utilisant un r√©seau de neurones siamois avec pipeline MLOps complet**

[Installation](#-installation) ‚Ä¢ [Utilisation](#-utilisation) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [API](#-api) ‚Ä¢ [MLOps](#-mlops)

</div>

---

## üìã Table des mati√®res

- [√Ä propos](#-√†-propos)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Architecture du projet](#-architecture-du-projet)
- [Architecture du mod√®le](#-architecture-du-mod√®le)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [API REST](#-api-rest)
- [Pipeline MLOps](#-pipeline-mlops)
- [Docker & D√©ploiement](#-docker--d√©ploiement)
- [R√©sultats](#-r√©sultats)
- [Technologies utilis√©es](#-technologies-utilis√©es)
- [Contribuer](#-contribuer)

---

## üéØ √Ä propos

Ce projet impl√©mente une solution MLOps compl√®te pour la **r√©solution d'entit√©s** (Entity Resolution) en utilisant un **R√©seau de Neurones Siamois** (Siamese Neural Network). Il permet d'identifier si deux entit√©s (personnes, organisations, etc.) repr√©sentent la m√™me entit√© r√©elle malgr√© des variations dans leur repr√©sentation textuelle.

### Cas d'usage

- ‚úÖ D√©duplication de bases de donn√©es clients
- ‚úÖ Correspondance d'identit√©s entre syst√®mes
- ‚úÖ D√©tection de doublons dans les enregistrements
- ‚úÖ V√©rification d'identit√© automatis√©e
- ‚úÖ Fusion de donn√©es multi-sources

---

## ‚ú® Fonctionnalit√©s

### ü§ñ Machine Learning

- **R√©seau Siamois Bidirectionnel LSTM** avec couches d'attention
- **M√©triques de similarit√© multiples** : Distance euclidienne, similarit√© cosinus, distance de Manhattan
- **Preprocessing avanc√©** avec tokenisation et normalisation de texte
- **Gestion du d√©s√©quilibre des classes** avec g√©n√©ration intelligente de paires n√©gatives

### üåê Application Web

- **Interface utilisateur intuitive** avec Flask
- **3 modes de pr√©diction** :
  - Comparaison simple (paire unique)
  - Traitement par lot (batch)
  - Recherche en base de donn√©es
- **API REST compl√®te** avec documentation JSON

### üîÑ Pipeline MLOps

- **Pipeline Kubeflow** complet pour l'entra√Ænement et le d√©ploiement
- **Containerisation Docker** pour portabilit√©
---

## üèóÔ∏è Architecture du projet

```mermaid
graph TB
    subgraph Data["üìä Donn√©es"]
        A[Source CSV] --> B[Preprocessing]
        C[Reference CSV] --> B
        B --> D[Dataset √âquilibr√©]
    end
    
    subgraph Model["üß† Mod√®le"]
        D --> E[Tokenization]
        E --> F[Siamese Network]
        F --> G[Training]
        G --> H[Mod√®le Entra√Æn√©]
    end
    
    subgraph Deploy["üöÄ D√©ploiement"]
        H --> I[Validation]
        I --> J{Performance OK?}
        J -->|Oui| K[D√©ploiement]
        J -->|Non| G
        K --> L[API Flask]
    end
    
    subgraph Use["üíª Utilisation"]
        L --> M[Interface Web]
        L --> N[API REST]
        M --> O[Pr√©dictions]
        N --> O
    end
    
    style Data fill:#e1f5ff
    style Model fill:#fff4e1
    style Deploy fill:#e8f5e9
    style Use fill:#f3e5f5
```

---

## üß† Architecture du mod√®le

### R√©seau Siamois

Le mod√®le utilise une architecture siamoise avec des poids partag√©s pour encoder les deux entit√©s :

```mermaid
graph LR
    subgraph Input["Entr√©es"]
        A[Entit√© 1] 
        B[Entit√© 2]
    end
    
    subgraph Embedding["Embedding Partag√©"]
        C[Embedding Layer<br/>dim=128]
    end
    
    subgraph Encoder["Encodeur Partag√©"]
        D[Bi-LSTM<br/>units=64]
        E[Global MaxPooling]
        F[Dense 128 + BN]
        G[Dense 64 + BN]
    end
    
    subgraph Similarity["M√©triques de Similarit√©"]
        H[Distance Euclidienne]
        I[Similarit√© Cosinus]
        J[Distance Manhattan]
    end
    
    subgraph Output["Classification"]
        K[Concatenation]
        L[Dense 32]
        M[Dense 16]
        N[Sigmoid]
        O[Match/No-Match]
    end
    
    A --> C
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    G --> I
    G --> J
    H --> K
    I --> K
    J --> K
    K --> L
    L --> M
    M --> N
    N --> O
    
    style Input fill:#e3f2fd
    style Embedding fill:#fff3e0
    style Encoder fill:#e8f5e9
    style Similarity fill:#fce4ec
    style Output fill:#f3e5f5
```

### Couches Personnalis√©es

Le mod√®le inclut trois couches custom TensorFlow pour calculer les similarit√©s :

1. **EuclideanDistanceLayer** : `‚àöŒ£(xi - yi)¬≤`
2. **CosineSimilarityLayer** : `(x¬∑y) / (||x|| ||y||)`
3. **ManhattanDistanceLayer** : `Œ£|xi - yi|`

---

## üì¶ Installation

### Pr√©requis

- Python 3.9+
- pip
- (Optionnel) Docker
- (Optionnel) Kubernetes cluster avec Kubeflow

### Installation locale

```bash
# Cloner le repository
git clone https://github.com/mounirlamsayah/Entity_Resolution_MLOps.git
cd Entity_Resolution_MLOps

# Cr√©er un environnement virtuel
python -m venv env
source env/bin/activate  # Linux/Mac
# ou
env\Scripts\activate  # Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

### Installation avec Docker

```bash
# Construire l'image
docker build -f docker/Dockerfile -t entity-matcher:latest .

# Ou utiliser docker-compose
docker-compose -f docker/docker-compose.yaml up
```

---

## üöÄ Utilisation

### 1Ô∏è‚É£ Pr√©paration des donn√©es

Placez vos fichiers CSV dans le dossier `data/` :
- `source_final.csv` : donn√©es source
- `reference_final.csv` : donn√©es de r√©f√©rence

```bash
python src/data_preprocessing.py
```

**Sorties** :
- `models/X1_train.npy`, `X2_train.npy`, `y_train.npy` : donn√©es d'entra√Ænement
- `models/X1_test.npy`, `X2_test.npy`, `y_test.npy` : donn√©es de test
- `models/tokenizer.pkl` : tokenizer sauvegard√©
- `models/processed_dataset.csv` : dataset complet

### 2Ô∏è‚É£ Entra√Ænement du mod√®le

```bash
python src/model_training.py
```

**Sorties** :
- `models/siamese_entity_matcher.h5` : mod√®le entra√Æn√©
- `models/best_model.h5` : meilleur mod√®le (early stopping)
- `models/training_metrics.json` : m√©triques d'entra√Ænement
- `models/training_history.png` : courbes d'apprentissage

### 3Ô∏è‚É£ Lancement de l'application

```bash
python src/app.py
```

Acc√©dez √† l'interface web : **http://localhost:5000**

---

## üåê API REST

### Endpoints disponibles

#### 1. Pr√©diction simple

```bash
POST /api/predict
Content-Type: application/json

{
  "text1": "Jean Dupont 123 rue de la Paix Paris CIN123456",
  "text2": "DUPONT Jean 123 RUE PAIX PARIS CIN123456"
}
```

**R√©ponse** :
```json
{
  "text1": "Jean Dupont 123 rue de la Paix Paris CIN123456",
  "text2": "DUPONT Jean 123 RUE PAIX PARIS CIN123456",
  "similarity_score": 0.9234,
  "is_match": true,
  "confidence": "High",
  "timestamp": "2025-10-05T14:30:00"
}
```

#### 2. Pr√©diction par lot

```bash
POST /api/batch_predict
Content-Type: application/json

{
  "pairs": [
    {"text1": "Entity A1", "text2": "Entity A2"},
    {"text1": "Entity B1", "text2": "Entity B2"}
  ]
}
```

#### 3. Recherche en base

```bash
POST /api/match_entity
Content-Type: application/json

{
  "query_entity": "Jean Dupont Paris",
  "database_entities": ["DUPONT Jean", "Pierre Martin", "Marie Dubois"],
  "threshold": 0.5
}
```

#### 4. √âvaluation du mod√®le

```bash
POST /api/evaluate
Content-Type: application/json

{
  "test_data_path": "models/processed_dataset.csv"
}
```

#### 5. Health check

```bash
GET /health
```

# üîÑ Pipeline MLOps

## üöÄ Kubeflow Pipeline

Le projet inclut un pipeline **Kubeflow** quasi-complet avec **5 composants impl√©ment√©s**.

> üìù **Note :** En raison de contraintes de ressources informatiques, je n'ai pas pu acc√©der √† une interface Kubeflow d√©ploy√©e pour tester le pipeline en conditions r√©elles.  
> Cependant, **le code du pipeline est enti√®rement d√©velopp√©** et il ne reste qu'une petite partie de finalisation pour le rendre **100% op√©rationnel** en production.  
> Le pipeline peut √™tre compil√© et est pr√™t pour √™tre d√©ploy√© sur un cluster Kubeflow fonctionnel.

---

```mermaid
graph LR
    A[1. Data<br/>Preprocessing] --> B[2. Model<br/>Training]
    B --> C[3. Model<br/>Evaluation]
    C --> D[4. Model<br/>Validation]
    D --> E[5. Model<br/>Deployment]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#fce4ec
    style E fill:#f3e5f5

## üì¶ √âtat du pipeline

| Composant          | Statut       | Description                          |
| ------------------ | ------------ | ------------------------------------ |
| Data Preprocessing | ‚úÖ Impl√©ment√© | Chargement et traitement des donn√©es |
| Model Training     | ‚úÖ Impl√©ment√© | Entra√Ænement du r√©seau siamois       |
| Model Evaluation   | ‚úÖ Impl√©ment√© | √âvaluation sur jeu de test           |
| Model Validation   | ‚úÖ Impl√©ment√© | Validation selon seuils d√©finis      |
| Model Deployment   | üîÑ En cours  | D√©ploiement conditionnel du mod√®le   |

## ‚öôÔ∏è Compiler le pipeline

# Compiler le pipeline en fichier YAML
python kubeflow/pipeline.py

# G√©n√®re deux fichiers :
# - entity_matching_pipeline.yaml (pipeline principal)
# - entity_matching_retrain_pipeline.yaml (pipeline de retraining)

##‚ñ∂Ô∏è Ex√©cution du pipeline (quand Kubeflow disponible)

### Via l‚Äôinterface Kubeflow UI

1. Se connecter √† l'interface Kubeflow
2. Uploader le fichier entity_matching_pipeline.yaml
3. Cr√©er une exp√©rience "entity-matching"
4. Lancer un run avec les param√®tres souhait√©s

## üîß Param√®tres du pipeline

| Param√®tre     | Description                    | D√©faut               |
| ------------- | ------------------------------ | -------------------- |
| epochs        | Nombre d'√©poques               | 10                   |
| batch_size    | Taille du batch                | 32                   |
| learning_rate | Taux d'apprentissage           | 0.001                |
| min_accuracy  | Seuil de validation (accuracy) | 0.7                  |
| min_f1        | Seuil de validation (F1-score) | 0.7                  |
| model_name    | Nom du mod√®le                  | entity-matcher-model |
| model_version | Version du mod√®le              | v1                   |

## üîÅ Pipeline de Retraining

Un second pipeline est disponible pour le fine-tuning avec de nouvelles donn√©es :

# Compiler le pipeline de retraining
python kubeflow/pipeline.py

Ce pipeline utilise :

  - Un learning rate plus faible (0.0001)

  - Moins d'√©poques (5)

  - Seuils de validation plus √©lev√©s (0.75)

## üê≥ Docker & D√©ploiement

Docker Compose

# Lancer l'API
docker-compose -f docker/docker-compose.yaml up api

# Ex√©cuter le preprocessing
docker-compose -f docker/docker-compose.yaml up preprocess

# Ex√©cuter l'entra√Ænement
docker-compose -f docker/docker-compose.yaml up train


## üåç Variables d'environnement

MODEL_PATH=/app/models
DATA_PATH=/app/data
FLASK_RUN_PORT=5000
PYTHONUNBUFFERED=1

## üíæ Volumes persistants

-   ./models:/app/models ‚Üí mod√®les entra√Æn√©s

-   ./data:/app/data ‚Üí donn√©es source

-   ./logs:/app/logs ‚Üí logs d'ex√©cution

## üìä R√©sultats

| M√©trique  | Score   |
| --------- | ------- |
| Accuracy  | ~85‚Äì90% |
| Precision | ~87‚Äì92% |
| Recall    | ~83‚Äì88% |
| F1-Score  | ~85‚Äì90% |


## üõ†Ô∏è Technologies utilis√©es

### Machine Learning & Deep Learning
- **TensorFlow 2.13** - Framework ML
- **Keras** - API haut niveau
- **scikit-learn** - M√©triques et preprocessing
- **NumPy & Pandas** - Manipulation de donn√©es

### NLP & Text Processing
- **RapidFuzz** - Similarit√© de cha√Ænes
- **Tokenizer Keras** - Tokenisation

### Web & API
- **Flask 2.3** - Framework web
- **RESTful API** - Architecture API

### MLOps & DevOps
- **Kubeflow 2.0** - Pipeline ML
- **Docker** - Containerisation
- **Kubernetes** - Orchestration

### Visualisation
- **Matplotlib & Seaborn** - Graphiques

---

## ü§ù Contribuer

Les contributions sont les bienvenues ! Voici comment participer :

1. **Fork** le projet
2. **Cr√©er** une branche feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** vos changements (`git commit -m 'Add AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrir** une Pull Request

### Guidelines

- Suivre le style de code existant
- Ajouter des tests pour les nouvelles fonctionnalit√©s
- Mettre √† jour la documentation
- S'assurer que tous les tests passent

---

## üìù Roadmap

- [ ] Ajouter le support des embeddings pr√©-entra√Æn√©s (BERT, GPT)
- [ ] Impl√©menter un syst√®me de cache pour les pr√©dictions
- [ ] Ajouter des m√©triques de monitoring Prometheus
- [ ] Support multi-langues
- [ ] Interface CLI pour batch processing
- [ ] Int√©gration avec Airflow pour orchestration

---

## üêõ Issues connues

Consultez la [page des issues](https://github.com/mounirlamsayah/Entity_Resolution_MLOps/issues) pour les probl√®mes connus et les demandes de fonctionnalit√©s.

---


## üë§ Auteur

**Mounir Lamsayah**

- Email: mounirlamssiyah@gmail.com
- GitHub: [@mounirlamsayah](https://github.com/mounirlamsayah)
- LinkedIn: [Mounir Lamsayah](https://linkedin.com/in/mounir-lamsayah)

---


## üìö R√©f√©rences

- [Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)
- [Learning Text Similarity with Siamese Recurrent Networks](https://aclanthology.org/W16-1617.pdf)
- [Entity Resolution in Practice](https://dl.acm.org/doi/10.1145/3442381.3449951)

---

<div align="center">

**‚≠ê Si ce projet vous a √©t√© utile, n'h√©sitez pas √† lui donner une √©toile ! ‚≠ê**

Made with ‚ù§Ô∏è by Mounir Lamsayah

</div>
