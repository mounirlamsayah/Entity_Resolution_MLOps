# üîç Entity Resolution MLOps

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13.0-orange.svg)
![Flask](https://img.shields.io/badge/Flask-2.3.2-green.svg)
![Kubeflow](https://img.shields.io/badge/Kubeflow-2.0.1-purple.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**Syst√®me intelligent de r√©solution d'entit√©s utilisant un r√©seau de neurones siamois avec pipeline MLOps complet**

[Installation](#-installation) ‚Ä¢ [D√©marrage rapide](#-d√©marrage-rapide) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [API](#-api-rest) ‚Ä¢ [MLOps](#-pipeline-mlops)

</div>

---

## üìã Table des mati√®res

- [√Ä propos](#-√†-propos)
- [Fonctionnalit√©s principales](#-fonctionnalit√©s-principales)
- [Architecture](#-architecture)
  - [Vue d'ensemble du syst√®me](#vue-densemble-du-syst√®me)
  - [Architecture du mod√®le](#architecture-du-mod√®le-siamois)
- [Installation](#-installation)
- [D√©marrage rapide](#-d√©marrage-rapide)
- [Utilisation d√©taill√©e](#-utilisation-d√©taill√©e)
- [API REST](#-api-rest)
- [Pipeline MLOps](#-pipeline-mlops)
- [Docker & D√©ploiement](#-docker--d√©ploiement)
- [R√©sultats](#-r√©sultats)
- [Technologies](#-technologies-utilis√©es)
- [Roadmap](#-roadmap)
- [Contribution](#-contribuer)
- [Licence](#-licence)
- [Contact](#-auteur)

---

## üéØ √Ä propos

Ce projet impl√©mente une **solution MLOps compl√®te** pour la r√©solution d'entit√©s (Entity Resolution) en utilisant un **R√©seau de Neurones Siamois** (Siamese Neural Network). Le syst√®me permet d'identifier si deux entit√©s (personnes, organisations, etc.) repr√©sentent la m√™me entit√© r√©elle malgr√© des variations dans leur repr√©sentation textuelle.

### üé™ Cas d'usage

| Domaine | Application |
|---------|-------------|
| üè¢ **Business** | D√©duplication de bases de donn√©es clients |
| üîó **Int√©gration** | Correspondance d'identit√©s entre syst√®mes |
| üóÇÔ∏è **Data Quality** | D√©tection de doublons dans les enregistrements |
| üõ°Ô∏è **S√©curit√©** | V√©rification d'identit√© automatis√©e |
| üîÑ **ETL** | Fusion de donn√©es multi-sources |

---

## ‚ú® Fonctionnalit√©s principales

### ü§ñ Machine Learning

- ‚úÖ **R√©seau Siamois Bidirectionnel LSTM** avec couches d'attention
- ‚úÖ **M√©triques de similarit√© multiples** : Distance euclidienne, similarit√© cosinus, distance de Manhattan
- ‚úÖ **Preprocessing avanc√©** avec tokenisation et normalisation de texte
- ‚úÖ **Gestion du d√©s√©quilibre des classes** avec g√©n√©ration intelligente de paires n√©gatives
- ‚úÖ **Early stopping & Model checkpointing** pour l'optimisation

### üåê Application Web

- ‚úÖ **Interface utilisateur intuitive** avec Flask
- ‚úÖ **3 modes de pr√©diction** :
  - Comparaison simple (paire unique)
  - Traitement par lot (batch processing)
  - Recherche en base de donn√©es
- ‚úÖ **API REST compl√®te** avec documentation JSON
- ‚úÖ **Monitoring en temps r√©el** des pr√©dictions

### üîÑ MLOps & DevOps

- ‚úÖ **Pipeline Kubeflow** pour l'entra√Ænement et le d√©ploiement automatis√©s
- ‚úÖ **Containerisation Docker** pour portabilit√© maximale
- ‚úÖ **Versioning des mod√®les** et tra√ßabilit√©
- ‚úÖ **Logs structur√©s** pour debugging et monitoring

---

## üèóÔ∏è Architecture

### Vue d'ensemble du syst√®me

```mermaid
graph TB
    subgraph Data["üìä Couche Donn√©es"]
        A[Source CSV] --> B[Preprocessing]
        C[Reference CSV] --> B
        B --> D[Dataset √âquilibr√©]
    end
    
    subgraph Model["üß† Couche Mod√®le"]
        D --> E[Tokenization]
        E --> F[Siamese Network]
        F --> G[Training]
        G --> H[Mod√®le Entra√Æn√©]
    end
    
    subgraph Deploy["üöÄ Couche D√©ploiement"]
        H --> I[Validation]
        I --> J{Performance OK?}
        J -->|Oui| K[D√©ploiement]
        J -->|Non| G
        K --> L[API Flask]
    end
    
    subgraph Use["üíª Couche Application"]
        L --> M[Interface Web]
        L --> N[API REST]
        M --> O[Pr√©dictions]
        N --> O
    end
    
    style Data fill:#e1f5ff
    style Model fill:#fff4e1
    style Deploy fill:#e8f5e9
    style Use fill:#f3e5f5
```

### Architecture du mod√®le siamois

Le mod√®le utilise une architecture √† **poids partag√©s** pour encoder les deux entit√©s de mani√®re sym√©trique :

```mermaid
graph LR
    subgraph Input["üî§ Entr√©es"]
        A[Entit√© 1] 
        B[Entit√© 2]
    end
    
    subgraph Embedding["üìö Embedding Partag√©"]
        C[Embedding Layer<br/>dim=128]
    end
    
    subgraph Encoder["üîÑ Encodeur Partag√©"]
        D[Bi-LSTM<br/>units=64]
        E[Global MaxPooling]
        F[Dense 128 + BN]
        G[Dense 64 + BN]
    end
    
    subgraph Similarity["üìè M√©triques"]
        H[Distance<br/>Euclidienne]
        I[Similarit√©<br/>Cosinus]
        J[Distance<br/>Manhattan]
    end
    
    subgraph Output["üéØ Classification"]
        K[Concatenation]
        L[Dense 32 + Dropout]
        M[Dense 16 + Dropout]
        N[Sigmoid]
        O[Match / No-Match]
    end
    
    A --> C
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    G --> I
    G --> J
    H --> K
    I --> K
    J --> K
    K --> L
    L --> M
    M --> N
    N --> O
    
    style Input fill:#e3f2fd
    style Embedding fill:#fff3e0
    style Encoder fill:#e8f5e9
    style Similarity fill:#fce4ec
    style Output fill:#f3e5f5
```

#### üîß Couches personnalis√©es

Le mod√®le inclut trois couches custom TensorFlow pour calculer les similarit√©s :

| Couche | Formule | Description |
|--------|---------|-------------|
| **EuclideanDistance** | `‚àöŒ£(xi - yi)¬≤` | Distance dans l'espace euclidien |
| **CosineSimilarity** | `(x¬∑y) / (‚Äñx‚Äñ ‚Äñy‚Äñ)` | Angle entre les vecteurs |
| **ManhattanDistance** | `Œ£\|xi - yi\|` | Distance de taxicab |

---

## üì¶ Installation

### Pr√©requis

| Outil | Version minimale | Obligatoire |
|-------|-----------------|-------------|
| Python | 3.9+ | ‚úÖ Oui |
| pip | 21.0+ | ‚úÖ Oui |
| Docker | 20.0+ | ‚ö™ Optionnel |
| Kubernetes + Kubeflow | 1.20+ / 2.0+ | ‚ö™ Optionnel |

### Installation locale

```bash
# 1. Cloner le repository
git clone https://github.com/mounirlamsayah/Entity_Resolution_MLOps.git
cd Entity_Resolution_MLOps

# 2. Cr√©er un environnement virtuel
python -m venv env

# Activer l'environnement
source env/bin/activate  # Linux/Mac
env\Scripts\activate     # Windows

# 3. Installer les d√©pendances
pip install -r requirements.txt
```

### Installation avec Docker

```bash
# Option 1 : Build manuel
docker build -f docker/Dockerfile -t entity-matcher:latest .

# Option 2 : Docker Compose (recommand√©)
docker-compose -f docker/docker-compose.yaml up
```

---

## üöÄ D√©marrage rapide

### En 3 √©tapes simples

```bash
# 1Ô∏è‚É£ Pr√©parer les donn√©es
python src/data_preprocessing.py

# 2Ô∏è‚É£ Entra√Æner le mod√®le
python src/model_training.py

# 3Ô∏è‚É£ Lancer l'application
python src/app.py
```

Acc√©dez √† l'interface web : **http://localhost:5000**

---

## üìñ Utilisation d√©taill√©e

### 1Ô∏è‚É£ Pr√©paration des donn√©es

#### Structure des donn√©es requises

Placez vos fichiers CSV dans le dossier `data/` avec la structure suivante :

**`source_final.csv`** et **`reference_final.csv`** :
```csv
nom,prenom,adresse,ville,cin
Dupont,Jean,123 rue de la Paix,Paris,CIN123456
```

#### Ex√©cution du preprocessing

```bash
python src/data_preprocessing.py
```

#### Sorties g√©n√©r√©es

| Fichier | Description |
|---------|-------------|
| `X1_train.npy`, `X2_train.npy`, `y_train.npy` | Donn√©es d'entra√Ænement |
| `X1_test.npy`, `X2_test.npy`, `y_test.npy` | Donn√©es de test |
| `tokenizer.pkl` | Tokenizer sauvegard√© |
| `processed_dataset.csv` | Dataset complet avec labels |

---

### 2Ô∏è‚É£ Entra√Ænement du mod√®le

```bash
python src/model_training.py
```

#### Param√®tres d'entra√Ænement

```python
EPOCHS = 50
BATCH_SIZE = 32
LEARNING_RATE = 0.001
VALIDATION_SPLIT = 0.2
```

#### Sorties g√©n√©r√©es

| Fichier | Description |
|---------|-------------|
| `siamese_entity_matcher.h5` | Mod√®le final entra√Æn√© |
| `best_model.h5` | Meilleur mod√®le (early stopping) |
| `training_metrics.json` | M√©triques d√©taill√©es |
| `training_history.png` | Courbes d'apprentissage |

---

### 3Ô∏è‚É£ Lancement de l'application

```bash
python src/app.py
```

#### Interface web

L'application propose 3 modes d'utilisation :

1. **Comparaison simple** : Comparer deux entit√©s individuelles
2. **Traitement par lot** : Upload d'un fichier CSV avec plusieurs paires
3. **Recherche en base** : Trouver les meilleures correspondances dans une base

---

## üåê API REST

### Documentation des endpoints

#### 1. üîç Pr√©diction simple

Compare deux entit√©s textuelles.

**Endpoint:** `POST /api/predict`

**Request:**
```json
{
  "text1": "Jean Dupont 123 rue de la Paix Paris CIN123456",
  "text2": "DUPONT Jean 123 RUE PAIX PARIS CIN123456"
}
```

**Response:**
```json
{
  "text1": "Jean Dupont 123 rue de la Paix Paris CIN123456",
  "text2": "DUPONT Jean 123 RUE PAIX PARIS CIN123456",
  "similarity_score": 0.9234,
  "is_match": true,
  "confidence": "High",
  "timestamp": "2025-10-05T14:30:00"
}
```

**Niveaux de confiance:**
- `High` : score ‚â• 0.8
- `Medium` : 0.5 ‚â§ score < 0.8
- `Low` : score < 0.5

---

#### 2. üì¶ Pr√©diction par lot

Traite plusieurs paires simultan√©ment.

**Endpoint:** `POST /api/batch_predict`

**Request:**
```json
{
  "pairs": [
    {"text1": "Entity A1", "text2": "Entity A2"},
    {"text1": "Entity B1", "text2": "Entity B2"}
  ]
}
```

**Response:**
```json
{
  "results": [
    {
      "text1": "Entity A1",
      "text2": "Entity A2",
      "similarity_score": 0.87,
      "is_match": true
    },
    {
      "text1": "Entity B1",
      "text2": "Entity B2",
      "similarity_score": 0.32,
      "is_match": false
    }
  ],
  "total_predictions": 2,
  "processing_time_ms": 45
}
```

---

#### 3. üîé Recherche en base

Trouve les meilleures correspondances pour une entit√©.

**Endpoint:** `POST /api/match_entity`

**Request:**
```json
{
  "query_entity": "Jean Dupont Paris",
  "database_entities": [
    "DUPONT Jean Paris",
    "Pierre Martin Lyon",
    "Marie Dubois Marseille"
  ],
  "threshold": 0.5
}
```

**Response:**
```json
{
  "query": "Jean Dupont Paris",
  "matches": [
    {
      "entity": "DUPONT Jean Paris",
      "similarity_score": 0.94,
      "rank": 1
    }
  ],
  "total_candidates": 3,
  "matches_found": 1
}
```

---

#### 4. üìä √âvaluation du mod√®le

√âvalue les performances sur un dataset de test.

**Endpoint:** `POST /api/evaluate`

**Request:**
```json
{
  "test_data_path": "models/processed_dataset.csv"
}
```

**Response:**
```json
{
  "accuracy": 0.8742,
  "precision": 0.8956,
  "recall": 0.8532,
  "f1_score": 0.8739,
  "confusion_matrix": [[425, 75], [68, 432]],
  "test_samples": 1000
}
```

---

#### 5. ‚ù§Ô∏è Health check

V√©rifie l'√©tat de l'API et du mod√®le.

**Endpoint:** `GET /health`

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "tokenizer_loaded": true,
  "timestamp": "2025-10-05T14:30:00"
}
```

---

## üîÑ Pipeline MLOps

### Architecture Kubeflow

Le projet inclut un **pipeline Kubeflow quasi-complet** avec 5 composants impl√©ment√©s.

> üìù **Note importante :** En raison de contraintes de ressources informatiques, le pipeline n'a pas pu √™tre test√© sur une infrastructure Kubeflow d√©ploy√©e. Cependant, **le code est enti√®rement d√©velopp√©** et pr√™t pour le d√©ploiement en production. Il ne reste qu'une petite partie de finalisation pour le rendre 100% op√©rationnel.

```mermaid
graph LR
    A[1. Data<br/>Preprocessing] --> B[2. Model<br/>Training]
    B --> C[3. Model<br/>Evaluation]
    C --> D[4. Model<br/>Validation]
    D --> E[5. Model<br/>Deployment]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#fce4ec
    style E fill:#f3e5f5
```

### √âtat d'avancement des composants

| Composant | Statut | Description | Progression |
|-----------|--------|-------------|-------------|
| **Data Preprocessing** | ‚úÖ Complet | Chargement et traitement des donn√©es | 100% |
| **Model Training** | ‚úÖ Complet | Entra√Ænement du r√©seau siamois | 100% |
| **Model Evaluation** | ‚úÖ Complet | √âvaluation sur jeu de test | 100% |
| **Model Validation** | ‚úÖ Complet | Validation selon seuils d√©finis | 100% |
| **Model Deployment** | üîÑ Presque termin√© | D√©ploiement conditionnel du mod√®le | 95% |

---

### Compilation du pipeline

```bash
# Compiler le pipeline principal
python kubeflow/pipeline.py

# G√©n√®re deux fichiers YAML :
# - entity_matching_pipeline.yaml (pipeline complet)
# - entity_matching_retrain_pipeline.yaml (pipeline de fine-tuning)
```

---

### Param√®tres configurables

| Param√®tre | Type | Description | Valeur par d√©faut |
|-----------|------|-------------|-------------------|
| `epochs` | int | Nombre d'√©poques d'entra√Ænement | 10 |
| `batch_size` | int | Taille du batch | 32 |
| `learning_rate` | float | Taux d'apprentissage | 0.001 |
| `min_accuracy` | float | Seuil de validation (accuracy) | 0.7 |
| `min_f1` | float | Seuil de validation (F1-score) | 0.7 |
| `model_name` | str | Nom du mod√®le | entity-matcher-model |
| `model_version` | str | Version du mod√®le | v1 |

---

### Ex√©cution du pipeline (quand Kubeflow disponible)

#### Via l'interface Kubeflow UI

1. Se connecter √† l'interface Kubeflow
2. Uploader le fichier `entity_matching_pipeline.yaml`
3. Cr√©er une exp√©rience "entity-matching"
4. Lancer un run avec les param√®tres souhait√©s

#### Via kubectl

```bash
# Appliquer le pipeline
kubectl apply -f entity_matching_pipeline.yaml

# Surveiller l'ex√©cution
kubectl get pods -n kubeflow
```

---

### Pipeline de Retraining

Un second pipeline optimis√© pour le fine-tuning avec de nouvelles donn√©es :

**Diff√©rences avec le pipeline principal :**
- Learning rate r√©duit : `0.0001` (vs `0.001`)
- Moins d'√©poques : `5` (vs `10`)
- Seuils de validation plus √©lev√©s : `0.75` (vs `0.70`)

```bash
# Compiler le pipeline de retraining
python kubeflow/pipeline.py
```

---

## üê≥ Docker & D√©ploiement

### Docker Compose

```bash
# Lancer l'API compl√®te
docker-compose -f docker/docker-compose.yaml up api

# Ex√©cuter le preprocessing seulement
docker-compose -f docker/docker-compose.yaml up preprocess

# Ex√©cuter l'entra√Ænement seulement
docker-compose -f docker/docker-compose.yaml up train
```

---

### Variables d'environnement

Cr√©ez un fichier `.env` √† la racine :

```bash
# Chemins des donn√©es et mod√®les
MODEL_PATH=/app/models
DATA_PATH=/app/data

# Configuration Flask
FLASK_RUN_PORT=5000
FLASK_ENV=production

# Configuration Python
PYTHONUNBUFFERED=1
PYTHONPATH=/app

# Configuration du mod√®le
MAX_SEQUENCE_LENGTH=100
EMBEDDING_DIM=128
```

---

### Volumes persistants

| Volume local | Volume container | Description |
|--------------|------------------|-------------|
| `./models` | `/app/models` | Mod√®les entra√Æn√©s et tokenizers |
| `./data` | `/app/data` | Donn√©es source et preprocess√©es |
| `./logs` | `/app/logs` | Logs d'ex√©cution et m√©triques |

---

### Build personnalis√©

```bash
# Build avec tag personnalis√©
docker build -f docker/Dockerfile \
  -t entity-matcher:v1.0.0 \
  --build-arg PYTHON_VERSION=3.9 \
  .

# Push vers un registry
docker tag entity-matcher:v1.0.0 myregistry/entity-matcher:v1.0.0
docker push myregistry/entity-matcher:v1.0.0
```

---

## üìä R√©sultats

### M√©triques de performance

| M√©trique | Score | D√©tails |
|----------|-------|---------|
| **Accuracy** | 85-90% | Taux de pr√©dictions correctes |
| **Precision** | 87-92% | Ratio de vrais positifs sur positifs pr√©dits |
| **Recall** | 83-88% | Ratio de vrais positifs d√©tect√©s |
| **F1-Score** | 85-90% | Moyenne harmonique precision/recall |

### Matrice de confusion (exemple)

```
                Pr√©dit Non-Match    Pr√©dit Match
R√©el Non-Match        425              75
R√©el Match             68             432
```

### Courbes d'apprentissage

Le mod√®le converge g√©n√©ralement apr√®s 30-40 √©poques avec early stopping.

---

## üõ†Ô∏è Technologies utilis√©es

### Machine Learning & Deep Learning

| Technologie | Version | Usage |
|-------------|---------|-------|
| **TensorFlow** | 2.13.0 | Framework ML principal |
| **Keras** | inclus | API haut niveau |
| **scikit-learn** | 1.3+ | M√©triques et preprocessing |
| **NumPy** | 1.24+ | Calcul num√©rique |
| **Pandas** | 2.0+ | Manipulation de donn√©es |

### NLP & Text Processing

| Technologie | Version | Usage |
|-------------|---------|-------|
| **RapidFuzz** | 3.0+ | Similarit√© de cha√Ænes |
| **Keras Tokenizer** | inclus | Tokenisation de texte |

### Web & API

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Flask** | 2.3.2 | Framework web |
| **Flask-CORS** | 4.0+ | Gestion CORS |
| **RESTful API** | - | Architecture API |

### MLOps & DevOps

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Kubeflow** | 2.0.1 | Pipeline ML |
| **Docker** | 20.0+ | Containerisation |
| **Kubernetes** | 1.20+ | Orchestration |
| **Docker Compose** | 2.0+ | Orchestration locale |

### Visualisation & Monitoring

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Matplotlib** | 3.7+ | Graphiques statiques |
| **Seaborn** | 0.12+ | Graphiques statistiques |

---

## üìù Roadmap

### üöÄ Prochaines fonctionnalit√©s

- [ ] **Embeddings pr√©-entra√Æn√©s** : Support BERT, GPT, FastText
- [ ] **Cache Redis** : Syst√®me de cache pour acc√©l√©rer les pr√©dictions
- [ ] **Monitoring Prometheus** : M√©triques de production
- [ ] **Support multi-langues** : Fran√ßais, Anglais, Arabe
- [ ] **CLI Tool** : Interface en ligne de commande pour batch processing
- [ ] **Airflow Integration** : Orchestration alternative √† Kubeflow

### üîß Am√©liorations techniques

- [ ] **Tests unitaires** : Coverage > 80%
- [ ] **CI/CD Pipeline** : GitHub Actions
- [ ] **Documentation API** : Swagger/OpenAPI
- [ ] **Containerisation GPU** : Support CUDA
- [ ] **Model Registry** : MLflow integration
- [ ] **A/B Testing** : Framework de test de mod√®les

---

## üêõ Issues connues

### Probl√®mes identifi√©s

1. **Kubeflow Pipeline** : N√©cessite finalisation du composant de d√©ploiement (95% termin√©)
2. **Performance** : Temps de pr√©diction augmente avec la longueur des textes (>200 tokens)
3. **M√©moire** : Charge importante lors du traitement batch (>10k paires)

### Workarounds

- **Kubeflow** : Pipeline compilable et testable localement
- **Performance** : Utiliser le batch processing avec taille r√©duite
- **M√©moire** : Ajuster le param√®tre `batch_size` dans l'API

Consultez la [page des issues](https://github.com/mounirlamsayah/Entity_Resolution_MLOps/issues) pour plus de d√©tails.

---

## ü§ù Contribuer

Les contributions sont les bienvenues ! Voici comment participer :

### Processus de contribution

1. **Fork** le projet
2. **Cr√©er** une branche feature
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. **Commit** vos changements
   ```bash
   git commit -m 'Add: Amazing new feature'
   ```
4. **Push** vers la branche
   ```bash
   git push origin feature/AmazingFeature
   ```
5. **Ouvrir** une Pull Request

### Guidelines

- ‚úÖ Suivre le style de code existant (PEP 8)
- ‚úÖ Ajouter des tests pour les nouvelles fonctionnalit√©s
- ‚úÖ Mettre √† jour la documentation
- ‚úÖ S'assurer que tous les tests passent
- ‚úÖ D√©crire clairement les changements dans la PR

### Types de contributions recherch√©es

- üêõ **Bug fixes**
- ‚ú® **Nouvelles fonctionnalit√©s**
- üìù **Am√©lioration de la documentation**
- üé® **Am√©liorations UI/UX**
- ‚ö° **Optimisations de performance**

---

## üìÑ Licence

Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

## üë§ Auteur

**Mounir Lamsayah**

- üìß Email: [mounirlamssiyah@gmail.com](mailto:mounirlamssiyah@gmail.com)
- üêô GitHub: [@mounirlamsayah](https://github.com/mounirlamsayah)
- üíº LinkedIn: [Mounir Lamsayah](https://linkedin.com/in/mounir-lamsayah)

---

## üìö R√©f√©rences & Ressources

### Articles scientifiques

1. Koch et al. (2015) - [Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)
2. Mueller & Thyagarajan (2016) - [Learning Text Similarity with Siamese Recurrent Networks](https://aclanthology.org/W16-1617.pdf)
3. Christophides et al. (2021) - [Entity Resolution in Practice](https://dl.acm.org/doi/10.1145/3442381.3449951)

### Documentation technique

- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [Kubeflow Pipelines Guide](https://www.kubeflow.org/docs/components/pipelines/)
- [Flask Documentation](https://flask.palletsprojects.com/)

### Datasets & Benchmarks

- [Magellan Entity Matching](https://github.com/anhaidgroup/deepmatcher)
- [ZeroER Benchmark](https://github.com/chu-data-lab/ZeroER)

---

<div align="center">

### ‚≠ê Si ce projet vous a √©t√© utile, n'h√©sitez pas √† lui donner une √©toile ! ‚≠ê

---

Made with ‚ù§Ô∏è by **Mounir Lamsayah**

[‚¨Ü Retour en haut](#-entity-resolution-mlops)

</div>
